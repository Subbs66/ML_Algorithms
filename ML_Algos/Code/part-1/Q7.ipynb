{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessory libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "root=\"/home/subhash/Desktop/spam/nnfl assignment/\"\n",
    "data=pd.read_excel(os.path.join(root,'data3.xlsx'),header=None)\n",
    "data=data.to_numpy()\n",
    "np.random.shuffle(data)\n",
    "data[:,-1]=data[:,-1]-1\n",
    "print(data.shape)\n",
    "#now we obtain the shuffled set of data convinient to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes(data):\n",
    "    y=data[:,-1]\n",
    "    class0=[]\n",
    "    class1=[]\n",
    "    classes=[]\n",
    "    for insts in range(0,data.shape[0]):\n",
    "        if (y[insts]==0):\n",
    "            class0.append(data[insts])\n",
    "        elif (y[insts]==1):\n",
    "            class1.append(data[insts])\n",
    "    c0=np.array(class0)\n",
    "    c1=np.array(class1)\n",
    "    classes.append(c0)\n",
    "    classes.append(c1)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(classes,train_perc):\n",
    "    train=[]\n",
    "    test=[]\n",
    "    class_insts=int(30)\n",
    "    for cls in range(0,len(classes)):\n",
    "        np.random.shuffle(np.array(classes[cls]))\n",
    "        traintemp=classes[cls][0:class_insts,:]\n",
    "        train.append(traintemp)\n",
    "        testtemp=classes[cls][class_insts:,:]\n",
    "        test.append(testtemp)\n",
    "    train=np.array(train).reshape(((class_insts*2),5))\n",
    "    np.random.shuffle(train)\n",
    "    test=np.array(test).reshape((40,5))\n",
    "    np.random.shuffle(test)\n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into features and class value\n",
    "def split_x_y(data):\n",
    "    y=(data[:,-1]).reshape((data.shape[0],1))\n",
    "    x=np.delete(data,-1,1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 4)\n",
      "(60, 1)\n",
      "(40, 4)\n",
      "(40, 1)\n"
     ]
    }
   ],
   "source": [
    "classes=split_classes(data)\n",
    "train,test=split_train_test(classes,60)\n",
    "x_train,y_train=split_x_y(train)\n",
    "x_test,y_test=split_x_y(test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function, takes in a single numerical value\n",
    "def sigmoid(x):\n",
    "    y=1/(1+np.exp(-x))\n",
    "    return y\n",
    "#returns a single numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(w,x):\n",
    "    hyps=[]\n",
    "    for insts in range(0,x.shape[0]):\n",
    "        h=np.dot(w.T,x[insts])\n",
    "        hyp=sigmoid(h)\n",
    "        hyps.append(hyp)\n",
    "    return hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likelyhood function\n",
    "def likely_func(hyps,y):\n",
    "    likes=[]\n",
    "    for insts in range(0,y.shape[0]):\n",
    "        like=(y[insts]*np.log(hyps[insts]))+((1-y[insts])*np.log(1-hyps[insts]))\n",
    "        likes.append(like)\n",
    "    return(np.array(likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costavg(errors):\n",
    "    costav=np.mean(errors)\n",
    "    return(costav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivative of likelyhood function\n",
    "def dervlikef(hyps,y,x):\n",
    "    deriv=[]\n",
    "    for insts in range(0,x.shape[0]):\n",
    "        hyps[insts]=np.reshape((hyps[insts]),(1,1))\n",
    "        derv=np.dot(np.reshape((x[insts]),(1,4)).T,((y[insts]*(1-hyps[insts])-((1-y[insts])*(hyps[insts])))))\n",
    "        deriv.append(derv)\n",
    "        dW=np.squeeze(np.mean(deriv,axis=0,keepdims=True)/2)\n",
    "        dW=np.reshape(dW,(x.shape[1],1))\n",
    "    return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(w,dervlikef,alpha):\n",
    "    w=w+(alpha*dervlikef)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train,y_train,alpha,iters,x_test,y_test):\n",
    "    w=np.ones([4,1])\n",
    "    w_list=[]\n",
    "    for k in range(iters):\n",
    "        for insts in range(0,x_train.shape[0]):\n",
    "            w_list.append(w)\n",
    "            deriv=dervlikef(hypothesis(w,x_train),y_train,x_train)\n",
    "            w=update_parameters(w,deriv,alpha)\n",
    "        y_cap=hypothesis(w,x_test)\n",
    "        for insts in range(0,np.array(y_cap).shape[0]):\n",
    "            if (y_cap[insts]<0.5):\n",
    "                y_cap[insts]=0\n",
    "            else:\n",
    "                y_cap[insts]=1\n",
    "        y_cap=np.array(y_cap).reshape(y_test.shape)\n",
    "        true_pos=0\n",
    "        true_neg=0\n",
    "        false_pos=0\n",
    "        false_neg=0\n",
    "        for insts in range(0,y_test.shape[0]):\n",
    "            if (y_test[insts]==1):\n",
    "                if (y_cap[insts]==1):\n",
    "                    true_pos=true_pos+1\n",
    "                else:\n",
    "                    false_neg=false_neg+1\n",
    "            else:\n",
    "                if (y_cap[insts]==0):\n",
    "                    true_neg=true_neg+1\n",
    "                else:\n",
    "                    false_pos=false_pos+1\n",
    "        sensitivity=true_pos/(true_pos+false_neg)\n",
    "        specificity=true_neg/(true_neg+false_pos)\n",
    "        accuracy=(true_pos+true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "    return sensitivity,specificity,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "se,sp,acc=train(x_train,y_train,0.05,1,x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(se)\n",
    "print(sp)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
